{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c98d368",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92059ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comenzando...\n",
      "\n",
      "Modelo SoftMax (MLR) : Numeros\n"
     ]
    }
   ],
   "source": [
    "import time                                                 # para tiempo\n",
    "inicio=time.time()                                          # momento inicial\n",
    "print ('Comenzando...\\n')\n",
    "print ('Modelo SoftMax (MLR) : Numeros')    \n",
    "import pandas as pd                                         # dataframe\n",
    "import numpy as np                                          # numerical python, algebra lineal\n",
    "\n",
    "import matplotlib.pyplot as plt                             # plots, graficos\n",
    "import seaborn as sns                                       # plots\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import confusion_matrix                # metricas, matriz de confusion\n",
    "from scipy.optimize import minimize                         # minimizar, opt\n",
    "\n",
    "from sklearn.datasets import make_circles, load_boston      # datasets\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "import warnings                                             # avisos\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)  # elimino un warning por valores NaN en logaritmos o /0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b0b69cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(X,a):                                 # funcion logistica, sigmoide, funcion del modelo, con z=X*alfa, el producto escalar\n",
    "    return 1.0/(1.0+np.exp(-np.dot(X,a)))   # Boltzmann con pivote, alfa[i]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01bbff4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coste(X,a,y,lambda_reg):              # funcion coste, funcion a minimizar \n",
    "    return -(np.sum(np.log(f(X,a)))+np.dot((y-1).T,(np.dot(X,a))))/y.size + lambda_reg/(2.0*y.size)*np.dot(a[1:],a[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2c903e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_coste(X,a,y,lambda_reg):          # gradiente de la funcion coste con regularizacion\n",
    "    return (np.dot(X.T,(f(X,a)-y)))/y.size + lambda_reg/(2.0*y.size)*np.concatenate(([0], a[1:])).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3d77037",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizador(X):                # normalizador de X\n",
    "    X_media=X.mean(axis=0)          # media de X\n",
    "    X_std=X.std(axis=0)             # desviacion estandar de X\n",
    "    X_std[X_std==0]=1.0             # si hay alguna std=0 ponla a 1\n",
    "    X=(X-X_media)/X_std             # normaliza\n",
    "    \n",
    "    X=np.insert(X, 0, 1, axis=1)    # esta linea añade una columna de 1, feature engineering [1, f1, f2.., fn, f1f2...] (mejora un 10%)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a1e47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = pd.read_csv('DF.csv')\n",
    "print ('Datos leidos...')\n",
    "display(datos.head())\n",
    "matriz_datos=datos.values   \n",
    "print ('Dimensiones matriz de datos: {}'.format(matriz_datos.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cb8a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(matriz_datos[45,1:].reshape(20,20))  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3652ea6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=np.zeros((matriz_datos.shape[0],10))   \n",
    "print ('Dimension de Y: {}'.format(Y.shape))  \n",
    "print ('')\n",
    "for i in range(10):\n",
    "    Y[:,i]=np.where(matriz_datos[:,0]==i,1,0)\n",
    "print(Y[0:10,:]) # 10 primeras filas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d4656a",
   "metadata": {},
   "outputs": [],
   "source": [
    "etiquetas=matriz_datos[:,0]        # etiqueta, el numero en si, 42000 etiquetas\n",
    "X=matriz_datos[:,1:]               # datos numericos de los pixeles, cada columna es un pixel (variables indep)\n",
    "print ('Dimension original de X: {}'.format(X.shape)) \n",
    "print ('')\n",
    "X=X[:,X.sum(axis=0)!=0]            # se quitan las columnas=0 (la suma de los elementos es no nulo, no hay informacion)\n",
    "print ('Dimension limpia de X: {}'.format(X.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563ed711",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train=X[0:30000,:], Y[0:30000,:]        # datos de entranamiento\n",
    "X_train_sk=X_train.copy()                          # para sklearn\n",
    "\n",
    "X_test, Y_test=X[30000:,:], Y[30000:,:]            # datos de test\n",
    "X_test_sk=X_test.copy()                            # para sklearn\n",
    "\n",
    "print ('Dimensiones train: X={}, Y={}'.format(X_train.shape, Y_train.shape))  \n",
    "print ('')\n",
    "print ('Dimensiones test: X={}, Y={}'.format(X_test.shape, Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11df8be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "etiquetas_train=etiquetas[0:30000]       # etiquetas para entranamiento\n",
    "etiquetas_test=etiquetas[30000:]         # etiquetas para test\n",
    "\n",
    "print ('Dimensiones etiquetas train: {}'.format(etiquetas_train.shape))\n",
    "print ('')\n",
    "print ('Dimensiones etiquetas test: {}'.format(etiquetas_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86229ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=normalizador(X_train)\n",
    "X_test=normalizador(X_test)\n",
    "print ('Datos normalizados.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba82ddb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_inicial=np.random.rand(X_train.shape[1]) # valores iniciales de los parametros alfa\n",
    "\n",
    "A_opt=np.zeros((X_train.shape[1],10))        # se crea la matriz para los parametros optimizados, alfas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cd9498",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_reg=100.            # valor obtenido desde gridsearching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48883932",
   "metadata": {},
   "outputs": [],
   "source": [
    "inicio_opt=time.time()                       # inicio optimizacion\n",
    "for i in range(10):\n",
    "    print ('\\n\\nOptimizando {} frente al resto.'.format(i))\n",
    "\n",
    "    def opt_coste(a):                        # funcion a minimizar\n",
    "        return coste(X_train, a, Y_train[:,i], lambda_reg) \n",
    "\n",
    "    def opt_grad_coste(a):                   # gradiente \n",
    "        return grad_coste(X_train, a, Y_train[:,i], lambda_reg)\t\n",
    "\n",
    "    # metodo Nelder-Mead, Powell, CG, BFGS, Newton-CG, L-BFGS-B, TNC, COBYLA, SLSQP, trust-constr, \n",
    "    # dogleg, trust-ncg, trust-exact, trust-krylov (tambien custom)            \n",
    "    metodo='trust-constr'\n",
    "    print ('Optimizacion {}...'.format(metodo)) # minimizacion, optimizacion\n",
    "    i_opt=time.time() \n",
    "    modelo=minimize(opt_coste, val_inicial, method=metodo, jac=opt_grad_coste, tol=1e-4, options={'disp':True}) \n",
    "    print ('Hecho.')\n",
    "    print (\"Tiempo optimizacion: {:.2f} segundos.\" .format(time.time()-i_opt))  \n",
    "    A_opt[:,i]=modelo.x\n",
    "\n",
    "t_custom=time.time()-inicio_opt   # tiempo desde inicio hasta final minimizacion\n",
    "print ('\\nTiempo total optimizacion custom: {:.2f} segundos.\\n' .format(t_custom))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077a67cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=[]                  # etiquetas predichas\n",
    "y_prob=[]                  # probabilidades de las etiquetas predichas\n",
    "\n",
    "def resumen(datos):        # testeo\n",
    "    for e in datos:\n",
    "        nombre, etiqueta, Xs=e         \n",
    "        etiq=etiqueta.size\n",
    "        probs=np.zeros((etiq,2))      # etiquetas con su probabilidad\n",
    "        cuenta=0                      # conteo de aciertos\n",
    "        for muestra in range(etiq): \n",
    "            for n in range(10):\n",
    "                alfa=A_opt[:,n]       # parametros de softmax\n",
    "                probs[n,0]=n\n",
    "                probs[n,1]=f(Xs[muestra,:],alfa)      # evaluacion de la prediccion\n",
    "                             \n",
    "            probs=probs[probs[:,1].argsort()[::-1]]   # se pone la prob mas alta al principio\n",
    "            y_pred.append(probs[0,0])\n",
    "            y_prob.append(probs[0,1])\n",
    "            if probs[0,0]==etiqueta[muestra]:         # si se acierta +1\n",
    "                cuenta+=1\n",
    "        print (\"\\n{}\".format(nombre))\n",
    "        print (\"{} correctos de {} ==> {:.4}% correcto\".format(cuenta, etiq, cuenta/etiq*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cae1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "resumen([('Entranamiento  :', etiquetas_train, X_train)])\n",
    "resumen([('Test  :', etiquetas_test, X_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80db86f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Dimensiones matriz de parametros={}'.format(A_opt.shape))\n",
    "df=pd.DataFrame(A_opt, columns=[i+1 for i in range(A_opt.shape[1])])  # se guardan los parametros softmax en csv\n",
    "#df.to_csv('alfas.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89150aaf",
   "metadata": {},
   "source": [
    "## sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364f998f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e14517",
   "metadata": {},
   "outputs": [],
   "source": [
    "ini_opt_sk=time.time()\n",
    "logreg=LogisticRegression(C=0.01, penalty='l2', tol=0.0001, max_iter=70,\n",
    "                          solver='lbfgs', multi_class='multinomial').fit(X_train_sk, etiquetas_train)\n",
    "t_sklearn=time.time()-ini_opt_sk\n",
    "print ('\\nTiempo total optimizacion sklearn: {:.2f} segundos.\\n' .format(t_sklearn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2103fad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resumen_sk(datos):\n",
    "    for e in datos:\n",
    "        nombre, etiqueta, Xs=e\n",
    "        etiq=etiqueta.size\n",
    "        \n",
    "        y_pred_sk=logreg.predict(Xs)\n",
    "        \n",
    "        cuenta=0\n",
    "        for muestra in range(etiq):\n",
    "            if y_pred_sk[muestra]==etiqueta[muestra]:         \n",
    "                cuenta+=1\n",
    "        \n",
    "        print (\"\\n{}\".format(nombre))\n",
    "        print (\"{} correctos de {} ==> {:.4}% correcto\".format(cuenta, etiq, cuenta/etiq*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea345fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "resumen_sk([('Entranamiento  :', etiquetas_train, X_train_sk)])\n",
    "resumen_sk([('Test  :', etiquetas_test, X_test_sk)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37f4e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('SkLearn es {:.2f} veces más rapido.'.format(t_custom/t_sklearn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0de1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_sk=logreg.predict(X_test_sk)\n",
    "comp=[y_pred[30000:][i]==y_pred_sk[i] for i in range(len(y_pred[30000:]))]\n",
    "n_equal=len([e for e in comp if e==False])/len(y_pred_sk)\n",
    "\n",
    "print ('Hay una diferencia entre ambos modelos del {:.2f}%.'.format(n_equal*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e7e55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "resumen([('Entranamiento Custom:', etiquetas_train, X_train)])\n",
    "resumen([('Test Custom:', etiquetas_test, X_test)])\n",
    "print ('')\n",
    "resumen_sk([('Entranamiento SkLearn:', etiquetas_train, X_train_sk)])\n",
    "resumen_sk([('Test SkLearn:', etiquetas_test, X_test_sk)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clase",
   "language": "python",
   "name": "clase"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
